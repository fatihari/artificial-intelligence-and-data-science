{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "\n",
    "from PIL import ImageTk, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id     dx dx_type   age     sex localization\n",
       "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp\n",
       "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp\n",
       "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp\n",
       "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp\n",
       "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear\n",
       "...            ...           ...    ...     ...   ...     ...          ...\n",
       "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen\n",
       "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen\n",
       "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen\n",
       "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face\n",
       "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back\n",
       "\n",
       "[10015 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\HAM10000_metadata.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lesion_id     10015 non-null  object \n",
      " 1   image_id      10015 non-null  object \n",
      " 2   dx            10015 non-null  object \n",
      " 3   dx_type       10015 non-null  object \n",
      " 4   age           9958 non-null   float64\n",
      " 5   sex           10015 non-null  object \n",
      " 6   localization  10015 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 547.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Dataframein(**df**) içerisinde **dx** feature(column)'unu countplot yapılıyor. Yani içerisinde bulunan kanser hücresinden kaç tane olduğunu ve dağılımını grafikle bize gösteriyor.\n",
    "- **%matplotlib qt** eklentisinin düzgün çalışması(değerlerin doğru görüntülenebilmesi) için figure'un tam ekran yapılması gerekmektedir!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dx', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib qt5 \n",
    "# %matplotlib widget # embedded\n",
    "sns.countplot(x = \"dx\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Öncelikle image'lerin dosya konumları(path) dataFrame'e path adıyla sütun olarak eklenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder_name = 'img/'\n",
    "extension = \".jpg\"\n",
    "#sample image path = img_folder_name + image_id[i] + extension\n",
    "# ismi path olan, dosya yoluna eşit değerleri olan yeni column oluşturulur.\n",
    "df['path'] = [ img_folder_name + i + extension for i in df['image_id'] ]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- df['path']'in içerisindeki her bir satırı fonksiyon yapması için map kullanılır. \n",
    "- x = 'path' e karşılık gelir. \n",
    "- x pathindeki resmi aç diyoruz. \n",
    "- Ancak bu resmi biz array olarak tanımlamak ve tutmakistiyoruz, bu yüzden np.asarray cast'ı ekleriz.\n",
    "\n",
    "- Bu işlem birkaç dakika süreceği için aşağıda ```df.to_pickle(\"df.pkl\")``` işlemini yaparak, verilerin son halini df.pkl dosyasında tutmuş oluruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image\"] = df[\"path\"].map( lambda x: np.asarray(Image.open(x).resize((100,75))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "plt.imshow(df[\"image\"][0]) # imshow: bir matrisi image şeklinde gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string değerleri numeric değerlere kodlar(convert).\n",
    "df[\"dx_idx\"] = pd.Categorical(df[\"dx\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df.pkl\") # Yukarıda yaptığımız işlemleri her seferinde yapmak zahmetli. Verimizi convert edeceğimiz, verimizi depolayan bir pickle dosyası olduğunu bilmek yeterli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Read Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>dx_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0027419.jpg</td>\n",
       "      <td>[[[190, 153, 194], [192, 154, 196], [191, 153,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0025030.jpg</td>\n",
       "      <td>[[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0026769.jpg</td>\n",
       "      <td>[[[185, 127, 137], [189, 133, 147], [194, 136,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "\n",
       "                   path                                              image  \\\n",
       "0  img/ISIC_0027419.jpg  [[[190, 153, 194], [192, 154, 196], [191, 153,...   \n",
       "1  img/ISIC_0025030.jpg  [[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...   \n",
       "2  img/ISIC_0026769.jpg  [[[185, 127, 137], [189, 133, 147], [194, 136,...   \n",
       "\n",
       "   dx_idx  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"df.pkl\") # verilerimizi hızlıca yukarıdaki adımları yapmaya gerek kalmadan bu bloku debug ederiz, dataFrame nesnesine dönüştürürek.\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- df['image'] sütununu yazdırdığımızda indeksleriyle birlikte bir array görünümlü ama indeksi de olan bir tür olarak görülecektir. Bu yüzden ilk önce list sonrasında da array'e çevirerek tüm indekslerden kurtulmuş oluruz. \n",
    "\n",
    "- **x_train** burada bizim eğitilecek verilerimiz image dosyalarıdır. Bu image dosyaları üzerinde algoritmalar ve modeller uygulanacaktır. Ve daha sonra elimizde olan görüntüler bu x_train verileriyle karşılaştırılacaktır.\n",
    "- **x_test** görürsek bunun anlamı, eğitilmiş x_train verilerimizle, bunlardan ayrı hiç eğitilmemiş **yeni verilerimizi**, **x_train** verilerimize göre karşılaştırılacak ve yeni verilerimizin **target class** dediğimiz kanser türü (dx) sonuçları oluşturulacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(df[\"image\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  stardardization\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_train = (x_train - x_train_mean)/x_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **y_train** bizim target classlarımızdır. Yani outputumuz olan kanser hücresi türüdür. \n",
    "- Bu veri image dosyalarının olduğu verilerden(**x_train**) ayrı hesaplanacağı için ayrı tutulur.\n",
    "\n",
    "- Aşağıda **One Hot Encoding** yöntemi kullanılmıştır. Bu yöntemdeki mantık:\n",
    "**dx_idx** sütunu içerisinde 7 farklı sonuca(kanser hücresi türüne) karşılık gelen sayı vardır, bunlar: 0, 1, 2, 3, 4, 5, 6\n",
    "- **One Hot Encoding** yöntemiyle:\n",
    "> <br>\n",
    "> 0 yerine 0000000 => herbiri 7 adet rakamdan oluşur. (num_classes = 7)<br> \n",
    "> 1 yerine 0100000 <br>\n",
    "> 2 yerine 0010000 <br>\n",
    "> 3 yerine 0001000 <br>\n",
    "> 4 yerine 0000100 <br>\n",
    "> 5 yerine 0000010 <br>\n",
    "> 6 yerine 0000001 yazılır.<br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dx_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dx_idx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_592/2213969278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# one hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtarget_class_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dx_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dx_idx\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_class_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dx_idx'"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "target_class_count = len(pd.unique(df['dx_idx']))\n",
    "y_train = to_categorical(df[\"dx_idx\"], num_classes = target_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (10015, 75, 100, 3)\n",
      "y_train:  (10015, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train: \" , x_train.shape)\n",
    "print(\"y_train: \" , y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Building the Model => Bir Deep Learning Algoritması: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 100 3\n"
     ]
    }
   ],
   "source": [
    "x_train.shape # 10015 instance, 75x100, 3 (RGB color image)\n",
    "n_row = x_train.shape[1]\n",
    "n_col = x_train.shape[2]\n",
    "col_type = x_train.shape[3]\n",
    "print(n_row, n_col, col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (n_row, n_col, col_type)\n",
    "target_class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # Sırayla tüm CNN layerlerımızı adım adım eklememiz için gerekli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER 1: Convolutional Layer\n",
    "> <br>\n",
    "> Resmin özelliklerini saptamak için kullanılır.\n",
    "> <br> <br>\n",
    "- Bu katman CNN’nin ana yapı taşıdır. \n",
    "- Resmin özelliklerini algılamaktan sorumludur. \n",
    "- Bu katman, görüntüdeki düşük ve yüksek seviyeli özellikleri çıkarmak için resme bazı fitreler uygular. \n",
    "- Örneğin, bu filtre kenarları algılayacak bir filtre olabilir. Bu filtreler genellikle çok boyutludur ve piksel değerleri içerirler.\n",
    "- (5x5x3) özelliğinde bir matris için 5 matrisin yükseklik ve genişliğini, 3 matrisin derinliğini temsil eder.\n",
    "\n",
    "```python\n",
    "Conv2D(32, kernel_size = (3,3), activation = \"relu\", padding = \"Same\", input_shape = input_shape)\n",
    "```\n",
    "kodunu inceleyecek olursak,\n",
    "- 32:neron sayısı, \n",
    "- kernel_size = (3,3): convolutional filtre boyutu 3x3 matris, \n",
    "\n",
    "- activation = \"relu\": Bu bir ReLu activation function'udur. Genellikle CNN de kullanılır. Ana avantajı aynı anda tüm nöronları aktive etmemesidir. Yani bir nöron negatif değer üretirse, aktive edilmeyeceği anlamına gelir. Negatif değerler üreten nöronlar sıfır değerini alır. Bu durum, **ReLU**’nun Hiperbolik Tanjant ve Sigmoid fonksiyonundan daha verimli ve hızlı çalışmasını sağlar. Bu nedenle ReLU, çok katmanlı sinir ağlarında daha çok tercih edilir. \n",
    "\n",
    "- padding = \"Same\": Veri kaybını önlemek için\n",
    "- input_shape = input_shape: verinin boyutu ve rgb özelliği olması.\n",
    "\n",
    "#### Özetle\n",
    "1. **Convolution input** resmin(matrisin) üzerinde **convolutional filter**’ın kaydırılması sonucu yapılır. \n",
    "\n",
    "2. Çakışan sayılar çarpılır. \n",
    "3. Çarpım sonucu elde edilen sayılar toplanarak **feature map** (output) matrisine aktarılır. \n",
    "4. Bu işlem input resminin boyutunu düşürürken veri kaybına da sebep oluyor. Veri kaybını önlemek için **same padding** metodu kullanılıyor. **Same padding** input resminin etrafına sıfır değerlerinden oluşan bir **çerçeve** eklenmesine deniyor. Bu sayede veri kaybı önleniyor. \n",
    "5. **Feature map** resme ait bir **feature** tutar, örneğin input arabaysa, bir feature map arabanın farını tutabilir, fakat arabanın diğer tüm özellikleri yani kapısı, camı vs gibi tüm feature’ları tespit edebilmek için çok sayıda **feature map**’e ihtiyaç duyarız. \n",
    "6. **Convolution** işleminin ardından feature map’e bir **aktivasyon fonksiyonu** olan **reLu** uygulanır. İşlemin **reLu** fonksiyonuna sokulmasının sebebi eksi değerlerin(nöronların) sıfırlanmasıdır. \n",
    "7. İkinci kez bu **Convolutional Layer**'ı tekrar ekleriz. Bunun sebebi tecrübelere dayalıdır. Ancak esas sebep: İlk filtreyi uyguladığımızda, bir **Feature Map** oluşturuyor ve bir **özellik** türünü tespit ediyoruz. Ardından, ikinci bir filtre kullanıp başka bir **özellik** türünü algılayan ikinci bir **Feature Map** oluştururuz.\n",
    "8. İkinci kez CNL uygularken, input_shape yazmıyorum. Çünkü modelimi Sequential() bir yapıda kurdum. Sequential(feature1, feature2) => yani ilk baştaki işlemin sonucunda oluşan feature_map, artık 2. işlemin inputu olacak. Ancak ilk baştakinin inputunu mecbur belirtmem gerekir, 2. işlem gibi şanslı değil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\", padding = \"Same\", input_shape = input_shape))\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\", padding = \"Same\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER 2: Pooling Layer\n",
    "1. Bu katman, CovNet’teki ardışık **convolutional katmanları** arasına sıklıkla eklenen bir katmandır.\n",
    "\n",
    "2. Bu katmanın görevi, gösterimin kayma boyutunu ve network içindeki parametreleri ve hesaplama sayısını azaltmak içindir. Bu sayede ağdaki uyumsuzluk kontrol edilmiş olur. Bunun dışında **overfitting** (aşırı öğrenme) sorununu çözmek için de kullanılır.\n",
    "3. Birçok Pooling işlemleri vardır, fakat en popüleri **max pooling**’dir. \n",
    "4. Yine aynı prensipte çalışan **average pooling**, ve **L2-norm pooling** algoritmaları da vardır.\n",
    "5. Feature map matrisi üzerinde belirlenen ölçülerde bir pencere dolaştırılır. Pencere içerisinde ki max değerin alınmasıyla yapılan bir işlemdir. Bu sayede, sinir ağının doğru karar vermesi için için yeterli bilgiyi içeren daha küçük çıktıları kullanmış olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25)) # overfitting'i önlemek için dropout ekleriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER 3: Tekrardan, Yine => Convolutional Layer\n",
    "- Nöron sayısını bu sefer 32 değil de 64 yaptık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\", padding = \"Same\", input_shape = input_shape))\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\", padding = \"Same\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER 4: Tekrardan Pooling Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.5)) # overfitting'i önlemek için dropout ekleriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Layer 5: Flattening Layer\n",
    " 1. Genel olarak, sinir ağları(neural network), input verilerini tek boyutlu bir diziden alır.\n",
    " \n",
    " 2. **Convolution** ve **Pooling** işlemlerinden sonra ortaya çıkan matrisleri **n satır 1 sütundan** oluşan vektörlere dönüştürme işlemine **flattening** denmektedir. Örneğin: 2x2 => 4x1 ya da 3x3 => 9x1\n",
    " 3. Bu vektörler, son ve en önemli katman olan  **artificial neural network**’ün olduğu kısım olan **Fully Connected Layer**ın inputları olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Layer 6: Full Connected/Dense Layer\n",
    "- Girdi resmimizi sinir ağları ile eğitebileceğimiz kıvama getirildikten sonra (Yani matris halinde olan görselimiz düz bir vektör haline getirildikten sonra) geriye sadece klasik sinir ağlarındaki çalışma mantığı kalıyor. \n",
    "\n",
    "- Yine katmanlardaki nodelarda (düğüm) özellikler tutuluyor ve weight (ağırlık) ve bias değiştirilerek öğrenme sürecine giriliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128,activation=\"relu\")) # nöron sayısı ne kadar fazla olurs o kadar iyi ancak veri kapasitesi artacak.\n",
    "model.add(Dropout(0.5)) # overfitting'i önlemek için dropout ekleriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Layer 7: Output Layer\n",
    "- Output layer yine dense olacak(ANN).\n",
    "\n",
    "- Dikkat edilmesi nokta, outputta 7 farklı sonuçtan 1 tanesinin çıkabilmesi için burada **nöron sayısı** yerine **target class** sayısını gireriz.\n",
    "- Activation fonksiyonu olarak da **reLu** yerine **softmax** kullanılacaktır.\n",
    "- **Softmax** activasyonu **Target Class** sayısı **2**'den fazla ise kullanılan bir yöntemdir. (Bizim veri setinde **7 target class** var.)\n",
    "- Bu işlem sonucunda şu şekilde bir output dizisi ortaya çıkar:\n",
    "0.1 - 0.2 - 0.3 - 0.05 - 0.25 - 0.02 - 0.08\n",
    "- Yukarıdaki 7 tane elemanı olan target sınıfında en büyük değer 0.3'tür. Yani Yüzde 30 olasılığıyla sonuç 3. sıradaki classtır diyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(target_class_count, activation=\"softmax\"))\n",
    "model.summary() # özetleyeceğimiz kısım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelin derlenmesi **model.compile()** fonksiyonu ile yapılır. \n",
    "\n",
    "- Bu fonksiyon **optimizer**, **loss**(kayıp)  ve **metrics** (metrik) olmak üzere üç temel parametre alır. Farklı parametreler de kullanılabilir.\n",
    "1. **Optimizer**, öğrenme oranını(**learning rate**) kontrol eder. Optimizer olarak **“**Adam** kullanıyoruz. **Adam** genellikle birçok durumda kullanmak için iyi bir **optimizasyon** algoritmasıdır. **Adam** algoritması, training boyunca **learning rate**'i ayarlar.\n",
    "\n",
    "2. **Learning Rate** (Öğrenme oranı), model için optimal ağırlıkların ne kadar hızlı hesaplandığını belirler. Daha küçük bir **learning rate**, daha kesin ve iyi ağırlıklara (belirli bir noktaya kadar) yol açabilir, bu modelin daha **iyi** öğrenmesi anlamına gelir ancak ağırlıkların hesaplanması için gereken süre daha **uzun** olacağından dolayı eğitim(train) süresi uzayacaktır.\n",
    "3. **Loss** fonksiyonumu,training aşamasında giderek azalmasını bekleriz. Bu fonksiyon için **categorical_crossentropy** kullanacağız. Bu, sınıflandırma problemleri için en yaygın kullanılan fonksiyon türüdür.\n",
    "4. **Accuracy** de loss ile ters orantılı olarak artmalıdır. Bu model tahminleri doğru yapabiliyor anlamına gelir.\n",
    "5. Eğitim(Train) sırasında modelin nasıl bir performans gösterdiğini yorumlamak için her bir **epoch** sonunda **validation(test)** seti ile elde edilen **doğruluk** ve **loss** miktarını görmek için **accuracy** metriğini kullanırız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.0001) # The 'lr' argument is deprecated, so we use learnign_rate.\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **fit** fonksiyonu içerisine (**validation_data**=(X_test, y_test)) da yazılırdı. Bu projede test işlemi yapılmadığı için eklenmedi.\n",
    "\n",
    "2. **Batch Size**: Batch sayısı modelin eğitilmesi aşamasında aynı anda kaç adet verinin işleneceği anlamına gelir. Ne kadar fazla yapılırsa RAM'e o kadar yük biner, ama işlem daha kısa sürer! :) Bu sayı genellikle 2'nin üssü olması yani 2,4,8,16,32 gibi sayıların olması tavsiye edilir.\n",
    "3. **Epoch**: \n",
    "- verilerin kaç kez **train** edeceğini söyler. Mesela 10000 adet resmimiz var. Epoch 2 ise tüm 10000 resim 2 kez train edilecektir.\n",
    "\n",
    "- bu değerin küçük bir sayı olması, eğitim süresini kısa tutarken modelin performansı tam gelişmemiş olabilirken, büyük bir sayı olması ise eğitim süresi çok uzun olur ve model gelişimini çoktan tamamlamış olabilir. Yani gereksiz eğitim yapılmış olabilir optimumm noktayı bulmakta zorlanabiliriz\n",
    "- Bunun için en iyi yöntem **büyük bir sayı** belirlenmesi ve modelin gelişimini tamamladığı noktada eğitimi durdurmaktır, buna **early stopping** deniyor. \n",
    "- Bu yöntem bu projede kullanılmadı ancak bu yöntem araştırılacak.\n",
    "- Accuracy değeri her epoch değerinde artıyor. Bu değerin durduğu epoch değerini gözlemek gerekir.\n",
    "4. **Shuffle**: Her **Epoch**ta, verilerin yerlerinin değiştirilmesidir. Eğitimin daha doğru olması için kullanılır. True ve False boolean değerleri alır.\n",
    "\n",
    "5. **Verbose**: 0, 1 ve 2 değerlerinden birisini alır. \n",
    "- 0 değeri, eğitim sırasında ekranda bir sonuç göstermezken, \n",
    "- 1 değeri, **progres bar** gibi anlık olarak güncellenen sonçları gösterir. \n",
    "- 2 değeri ise her bir epoch sonunda tek bir satır olarak çıktı verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = x_train,\n",
    "                    y = y_train,\n",
    "                    batch_size = 64, \n",
    "                    epochs = 50,\n",
    "                    verbose = 1,\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "##### Modelin performansını arttırmak için modelin ayarları ile oynamak, daha fazla katman veya nöron eklemek, verileri çoğaltmak veya daha güzel veriler seçmek gerekebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modeli train etme işlemi epoch değerine ve learning rate değerlerine göre uzun sürede gerçekleşebilir.\n",
    "\n",
    "- Bu yüzden mevcut modeli kaybetmek istemeyiz ve modeli bir yerde **my_model1.h5** adıyla kaydedebiliriz. \n",
    "- Özetle modelde learning rate ve epoch değerleriyle oynayarak yeni isimler verilebilir ve sonuçlar karşılaştırılabilir. Farklı seçenekleri kullanıcı arayüzünde gösterilecek Model1 veya Model2 diye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"my_model1.h5\") # yanlışlıkla debug etmemek için comment içerisine aldık.\n",
    "#model.save(\"my_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "model1 = load_model(\"my_model1.h5\")\n",
    "model2 = load_model(\"my_model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-Using our models to make predictions (Yeni veriler ile tahmin yapmak)\n",
    "\n",
    "- Modellerimizi yeni verilerle ilgili tahminlerde bulunmak için kullanmak istiyorsak, **model.predict()** fonksiyonunu kullanmamız gerekir. \n",
    "\n",
    "- Input olarak **test** verilerinden istediğimiz bir tanesini seçip verebiliriz.\n",
    "\n",
    "- Ben **5. satırda** bulunan veriyi alıp **tahminde** bulunmasını istedim. \n",
    "\n",
    "- Sonuç olarak %60 oranında meningioma tümörü çıktı. Modelin başarı oranına göre gayet başarılı bir sonuş olduğunu söyeyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>dx_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0027419.jpg</td>\n",
       "      <td>[[[190, 153, 194], [192, 154, 196], [191, 153,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0025030.jpg</td>\n",
       "      <td>[[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0026769.jpg</td>\n",
       "      <td>[[[185, 127, 137], [189, 133, 147], [194, 136,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>img/ISIC_0025661.jpg</td>\n",
       "      <td>[[[24, 11, 17], [26, 13, 22], [38, 21, 32], [5...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>img/ISIC_0031633.jpg</td>\n",
       "      <td>[[[134, 90, 113], [147, 102, 125], [159, 115, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                   path                                              image  \\\n",
       "0  img/ISIC_0027419.jpg  [[[190, 153, 194], [192, 154, 196], [191, 153,...   \n",
       "1  img/ISIC_0025030.jpg  [[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...   \n",
       "2  img/ISIC_0026769.jpg  [[[185, 127, 137], [189, 133, 147], [194, 136,...   \n",
       "3  img/ISIC_0025661.jpg  [[[24, 11, 17], [26, 13, 22], [38, 21, 32], [5...   \n",
       "4  img/ISIC_0031633.jpg  [[[134, 90, 113], [147, 102, 125], [159, 115, ...   \n",
       "\n",
       "   dx_idx  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       2  \n",
       "4       2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "y_train[index] # 10. indexin gerçekteki değeri, şimdi aşağıda tahminleme yapalım.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6577616e-02 1.2059943e-03 9.7919285e-01 1.3616077e-04 2.0780697e-04\n",
      "  2.6795720e-03 7.1016885e-08]]\n",
      "Maximum value:  0.97919285\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_train[index].reshape(1,75,100,3))\n",
    "print(y_pred)\n",
    "print(\"Maximum value: \",np.max(y_pred)) # Tüm olasılıkların toplamının 1 olmasını bekleriz.\n",
    "print(\"Sum: \", np.sum(y_pred)) # Tüm olasılıkların toplamının 1 olmasını bekleriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict result: 2\n",
      "Reel result: 2\n",
      "Reel cancer:  bkl\n",
      "Predict cancer:  bkl\n"
     ]
    }
   ],
   "source": [
    "reel_index = np.argmax(y_train[index])\n",
    "predict_index = np.argmax(y_pred)\n",
    "print(\"Predict result:\", predict_index)\n",
    "print(\"Reel result:\", np.argmax(y_train[index]))\n",
    "\n",
    "# predicted_cancer = list(df.dx.unique())[predict_index] #output\n",
    "# reel_cancer = list(df.dx.unique())[reel_index]\n",
    "\n",
    "# print(\"predicted cancer: \", predicted_cancer)\n",
    "# print(\"reel cancer: \", predicted_cancer)\n",
    "\n",
    "reel_filter = df[\"dx_idx\"]==reel_index\n",
    "reel_cancer=df[\"dx\"][reel_filter].unique()\n",
    "print(\"Reel cancer: \", reel_cancer[0])\n",
    "\n",
    "predict_filter = df[\"dx_idx\"]==predict_index\n",
    "predicted_cancer=df[\"dx\"][predict_filter].unique()\n",
    "print(\"Predict cancer: \", predicted_cancer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullanıcı arayüzünde,\n",
    "\n",
    "- 1 tane parent window => **window**\n",
    "\n",
    "- **window**'a bağlı 2 tane main frame => **frame_left** ve **frame_right**,\n",
    "- **frame_left**'e bağlı 2 tane sub frame => **f1** ve **f2**\n",
    "- **frame_right**'a bağlı 2 tane sub frame => **f3** ve **f4**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## global variables\n",
    "img_name = \"\"\n",
    "count = 0\n",
    "img_jpg = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent widget => window\n",
    "window = tk.Tk()\n",
    "window.geometry(\"1080x640\")\n",
    "window.wm_title(\"Skin Cancer Classification\")\n",
    "\n",
    "## frames\n",
    "frame_left = tk.Frame(window, width = 540, height = 640, bd = \"2\") #border size=bd=sınırlarının genişliği\n",
    "frame_left.grid(row = 0, column = 0)\n",
    "\n",
    "frame_right = tk.Frame(window, width = 540, height = 640, bd = \"2\")\n",
    "frame_right.grid(row = 0, column = 1)\n",
    "\n",
    "frame1 = tk.LabelFrame(frame_left, text = \"Image\", width = 540, height = 500)\n",
    "frame1.grid(row = 0, column = 0)\n",
    "\n",
    "frame2 = tk.LabelFrame(frame_left, text = \"Model and Save\", width = 540, height = 140)\n",
    "frame2.grid(row = 1, column = 0)\n",
    "\n",
    "frame3 = tk.LabelFrame(frame_right, text = \"Features\", width = 270, height = 640)\n",
    "frame3.grid(row = 0, column = 0)\n",
    "\n",
    "frame4 = tk.LabelFrame(frame_right, text = \"Result\", width = 270, height = 640)\n",
    "frame4.grid(row = 0, column = 1, padx = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame1\n",
    "def imageResize(img):\n",
    "    # For example: img.size= 1000x1200\n",
    "    basewidth = 500\n",
    "\n",
    "    # img.size[0] = 1000, So, 500/1000 = 0.5 = wpercent\n",
    "    wpercent = (basewidth/float(img.size[0]))    \n",
    "\n",
    "    # img.size[1] = 1200, So, 1200*0.5 = 600 = hsize\n",
    "    hsize = int((float(img.size[1])*float(wpercent))) \n",
    "\n",
    "    # img.resize boyutları => 500x600 olmuş oldu\n",
    "    img = img.resize((basewidth, hsize),Image.ANTIALIAS) # resize yaparken araları doldurmak için antialiasing yöntemi kullanılır. Ayrıntıya gerek yok.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImage():\n",
    "    \n",
    "    global img_name\n",
    "    global count # yalnızca bir resim görüntülenmesi sağlamak için\n",
    "    global img_jpg\n",
    "    \n",
    "    count += 1\n",
    "    if count != 1:\n",
    "        messagebox.showinfo(title = \"Warning\", message = \"Only one image can be opened\")\n",
    "    else:\n",
    "        img_name = filedialog.askopenfilename(initialdir = \"img\",title = \"Select an image file\")\n",
    "        \n",
    "        #02-Python GUI - Tkinter and PyQt5 with Real World Python Projects/04-Skin Cancer Classification Project with Tkinter/img/ISIC_0024306.jpg\n",
    "        img_jpg = img_name.split(\"/\")[-1].split(\".\")[0] # ISIC_0024306 (resim adı alınır)\n",
    "        # image label\n",
    "        tk.Label(frame1, text =img_jpg, bd = 3 ).pack(pady = 10)\n",
    "    \n",
    "        # open and show image\n",
    "        img = Image.open(img_name)\n",
    "        img = imageResize(img)\n",
    "        img = ImageTk.PhotoImage(img) # Tk kütüphanesiyle kullanabilmek için uygun formata sokmak zorundayız. \n",
    "        panel = tk.Label(frame1, image = img) # frame1'de duracak olan resmi belirttik.\n",
    "        panel.image = img\n",
    "        panel.pack(padx = 15, pady = 10)\n",
    "        \n",
    "        # image feature\n",
    "        data = pd.read_csv(\"data\\HAM10000_metadata.csv\")\n",
    "        cancer = data[data.image_id == img_jpg]\n",
    "        # print(cancer) dersek aşağıdaki gibi output verir. Size'ı 7 dir.\n",
    "        # lesion_id   image_id      dx  dx_type     age  sex   localization\n",
    "        # HAM_0000550 ISIC_0024306  nv  follow_up  45.0  male    trunk\n",
    "\n",
    "        for i in range(cancer.size):\n",
    "            x = 0.4 # labellar 0.1di biraz sağa koyuyorum\n",
    "            y = (i/10)/2\n",
    "            tk.Label(frame3, font = (\"Times\",12), text = str(cancer.iloc[0,i])).place(relx = x, rely = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menu\n",
    "menubar = tk.Menu(window)\n",
    "window.config(menu = menubar)\n",
    "file = tk.Menu(menubar)\n",
    "menubar.add_cascade(label = \"File\",menu = file)\n",
    "file.add_command(label = \"Open\", command = openImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame3\n",
    "def classification():\n",
    "    \n",
    "    if img_name != \"\" and models.get() != \"\": #image ve modeller boş olmaması lazım\n",
    "        \n",
    "        # model selection\n",
    "        if models.get() == \"Model1\":\n",
    "            classification_model = model1 # cnn'de kaydediğimiz model1\n",
    "        else:\n",
    "            classification_model = model2 # cnn'de kaydediğimiz model1\n",
    "        \n",
    "        z = df[df.image_id == img_jpg] # filtering\n",
    "        z = z.image.values[0].reshape(1,75,100,3) #values[0]=image_id column\n",
    "        \n",
    "        # datasetini train etmeden önce standardize etmiştik, aynı şekilde predict edilecek datayı da standardize ederiz.\n",
    "        z = (z - x_train_mean)/x_train_std\n",
    "\n",
    "        pred = classification_model.predict(z)[0]\n",
    "        p_index = np.argmax(pred)\n",
    "        p_filter = df[\"dx_idx\"]==p_index\n",
    "        pred_cancer=df[\"dx\"][p_filter].unique()\n",
    "        pred_cancer[0]\n",
    "    \n",
    "\n",
    "        print(\"Predict cancer: \", predicted_cancer[0])\n",
    "        print(\"Predict: \", pred)\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "            x = 0.5\n",
    "            y = (i/10)/2\n",
    "            \n",
    "            if i != p_index: #outputu farklı renkte yapacağız.\n",
    "                tk.Label(frame4,text = str(pred[i])).place(relx = x, rely = y)\n",
    "            else:\n",
    "                tk.Label(frame4,bg = \"yellow\",text = str(pred[i])).place(relx = x, rely = y)\n",
    "        \n",
    "        if chvar.get() == 1: #sonucları kaydedeceğiz. defaut 0 ayarlamıştık. 0 => seçili değil, 1 => seçili anlamına gelir.\n",
    "            \n",
    "            val = entry.get()\n",
    "            entry.config(state = \"disabled\") # enrtry'yi get ettikten sonra, disabled yapacağız.\n",
    "            path_name = val + \".txt\" # result1.txt\n",
    "            \n",
    "            save_txt = img_name + \"--\" + str(pred_cancer[0])\n",
    "            \n",
    "            text_file = open(path_name,\"w\")\n",
    "            text_file.write(save_txt)\n",
    "            text_file.close()\n",
    "        else:\n",
    "            print(\"Save is not selected\")\n",
    "    else:\n",
    "        messagebox.showinfo(title = \"Warning\", message = \"Choose image and Model First!\")\n",
    "        tk.Label(frame3, text = \"Choose image and Model First!\" ).place(relx = 0.1, rely = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"lesion_id\",\"image_id\",\"dx\",\"dx_type\",\"age\",\"sex\",\"localization\"]\n",
    "for i in range(len(columns)):\n",
    "    x = 0.1\n",
    "    y = (i/10)/2 #featureslerı alt alta artacak şekilde yazdırma için\n",
    "    tk.Label(frame3, font = (\"Times\",12), text = str(columns[i]) + \": \").place(relx = x, rely = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_button = tk.Button(frame3, bg = \"red\", bd = 4, font = (\"Times\", 13),activebackground = \"orange\", text = \"Classify\", command = classification)\n",
    "classify_button.place(relx = 0.1, rely = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 4 => classication labels\n",
    "labels = df.dx.unique()\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    x = 0.1\n",
    "    y = (i/10)/2\n",
    "    p_filter = df[\"dx_idx\"]==i\n",
    "    pred_cancer=df[\"dx\"][p_filter].unique()\n",
    "    tk.Label(frame4, font = (\"Times\",12), text = str(pred_cancer[0]) + \": \").place(relx = x, rely = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 2 \n",
    "# combo box\n",
    "model_selection_label = tk.Label(frame2, text = \"Choose classification model: \")\n",
    "model_selection_label.grid(row = 0, column = 0, padx = 5)\n",
    "\n",
    "models = tk.StringVar() #modelerimi string variable olarak okuyacağız.\n",
    "model_selection = ttk.Combobox(frame2, textvariable = models, values = (\"Model1\",\"Model2\"), state = \"readonly\")\n",
    "model_selection.grid(row = 0, column = 1, padx = 5)\n",
    "\n",
    "# check box\n",
    "chvar = tk.IntVar()\n",
    "chvar.set(0) # default 0\n",
    "xbox = tk.Checkbutton(frame2, text = \"Save Classification Result\", variable = chvar)\n",
    "xbox.grid(row = 1, column =0 , pady = 5)\n",
    "\n",
    "# entry\n",
    "entry = tk.Entry(frame2, width = 23)\n",
    "entry.insert(string = \"Saving name...\",index = 0) #placeholder => txt file name\n",
    "entry.grid(row = 1, column =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict cancer:  bkl\n",
      "Predict:  [3.3516500e-03 1.4763315e-03 9.6265286e-01 1.0186192e-02 7.5445464e-04\n",
      " 2.1565694e-02 1.2866633e-05]\n",
      "Save is not selected\n",
      "Predict cancer:  bkl\n",
      "Predict:  [0.02001467 0.15723969 0.2198111  0.02507233 0.04038553 0.5175485\n",
      " 0.01992822]\n",
      "Save is not selected\n"
     ]
    }
   ],
   "source": [
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78dbf5722967f313c4c7f2f73db293759ee911f3cc260e746cc2fb2541b961a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
