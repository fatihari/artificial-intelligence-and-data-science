{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nedir bu GANs ?\n",
    "* Eğitim setiyle aynı istatistiklere sahip, gerçeğinden ayırt edilemez yeni veriler üreten yapılardır.\n",
    "\n",
    "* GANs içerisinde 2 network vardır:\n",
    "  * **Generator**(Üretici ağ)         => Resimleri başlangıçta saçma sapan üreten, zamanla gerçek haline benzetmeye çalışan, yeni veri üreten yapı. (**Kalpazan**)\n",
    "  * **Discriminator**(Ayırt edici ağ) => Classifier görevi var. Üretilen data gerçek mi değil mi diye sorgulayacak. (**Dedektif**)\n",
    "* Zamanla Generator o kadar güzel resimler üretecek ki Discriminator fake mi gerçek mi anlayamayacak, Discriminator'u kandırmaya başlayacak! :)\n",
    "* <img src=\"img/gans.png\">\n",
    "* <img src=\"img/gans2.png\">\n",
    "* <img src=\"img/gans3.png\">\n",
    "* <img src=\"img/gans4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Articles\n",
    "- https://arxiv.org/pdf/1708.05509.pdf\n",
    "- https://arxiv.org/pdf/1609.04802.pdf\n",
    "- https://arxiv.org/pdf/1704.04086.pdf\n",
    "- https://github.com/pathak22/context-encoder\n",
    "- https://github.com/hanzhanggit/StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Input, ReLU\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Read Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert (-1,1) normalization\n",
    "x_train = (x_train.astype(np.float32)-127.5)/127.5\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGYUlEQVR4nO3dXYjVdR7H8TOT+cBmaijuZosx1WDZYlYXaxARrQRd1E0S0ZZFXURUN0JBdBM9XFUbsQt7EV0EPZAWwRIs2RP0MGhFbYZW9iBBSSWdslhQ53i66qrz/548M+P50Lxel379/88f4T0/8Mv/zEi3220BeUaH/QBAb+KEUOKEUOKEUOKEUHOq4frRDf4rF2bY1sObR3r9uZMTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQpVfjclg9tyzrpx35jd/4+iy1d+W106seWagZ/rFKS9fV84Xbl/QOFv+8JtT+myOjJMTQokTQokTQokTQokTQokTQokTQtlzDqD9/Gnl/IOz/jljn31oir+U8cMLHynnj5/7p8bZ01svKK/t7No90DPRm5MTQokTQokTQokTQokTQokTQokTQtlz9tBvj/nGWU/N2Gf/+/uxcv7gxPpyfvLK+n3QF854tpxftXBv4+zea5eW147dbs85nZycEEqcEEqcEEqcEEqcEEqcEEqcEGpW7jknLzqnnL+85l997nBsOX2oPV7OX7ni3ObhV9+U14633y7no/Pnl/P7tv2lnN+xdEfjbHLJZHkt08vJCaHECaHECaHECaHECaHECaFm5SrlpxVzy/lon59Z/VYlr15arys6n31Uzqfik7vWlvMnTnigzx3mNU5O+q+f5UeTf20IJU4IJU4IJU4IJU4IJU4IJU4INSv3nIsfmyjnl7/993I+0t5fzif37jnSR5o2N1zyYjk/brR5j0kWJyeEEieEEieEEieEEieEEieEEieEmpV7zn46Oz8e9iM02nPvunJ+/eL7+9yh/urMTXv/2jhb+OKu8tpOn0/myDg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ9Z5jvr673mG9cU+8xF43We8yJA8eU8/fuaf7e2wX7t5fXMr2cnBBKnBBKnBBKnBBKnBBKnBBKnBDKnjPMvrO75bzfHrOfja/eUM7Hn7PLTOHkhFDihFDihFDihFDihFDihFBWKUNwcOvKxtnEqgf6XF2vUtZMbCznp2/6tJz7esscTk4IJU4IJU4IJU4IJU4IJU4IJU4IZc85A+aMnVzO7z51c+NsSZ9Xwt45UH/2yrvrTWWn3a5vQAwnJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Sy55wBpzz9ZTlfO3fwn4lXvnRjOR//31sD35ssTk4IJU4IJU4IJU4IJU4IJU4IJU4IZc85gPbGdeX8ruX9vnt2XuNk456/lVeeftsn5dz3zv5+ODkhlDghlDghlDghlDghlDghlDghlD1nD3NWnFjOz791Wzk/brR5j9nPxM5Ty/l42/uas4WTE0KJE0KJE0KJE0KJE0KJE0JZpfSw644/l/Pn/vifKd3/wh0bGmdeCeMXTk4IJU4IJU4IJU4IJU4IJU4IJU4IZc/ZwzuX/qPP3xj8lbBWq9VadNPhxtlkuz2le/P74eSEUOKEUOKEUOKEUOKEUOKEUOKEUPacQ3Bo+aLG2bEHVxzFJ/m1zrf7GmfdAwfKa0fm1fvfY5YtHeiZWq1Wq7NscTnfvWnuwPf+LbqdkcbZqlv6vIO7f/9An+nkhFDihFDihFDihFDihFDihFDihFD2nEPw/JZHh/0Ijc5798rG2b6vjy+vXbLsx3K+7ZwnBnqmdGfceXM5H7ttYqD7OjkhlDghlDghlDghlDghlDghlFVKD5ftvKqcv3TmlqP0JEffm2ufHNpn/797sHF2qNv8daK/xSXvX1vOf3hv8NfZVrw+OfC1FScnhBInhBInhBInhBInhBInhBInhLLn7GHBxZ+X89X31a8IdWfwX3Xhqu/K+Uy+lrX6tevKefeLP0zp/mNbfmoebt8xpXsvae2e0nwYnJwQSpwQSpwQSpwQSpwQSpwQSpwQaqTb7TYO149uaB4C02Lr4c09f7+gkxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCjXS73WE/A9CDkxNCiRNCiRNCiRNCiRNCiRNC/Qy/F9Z69RGztAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[1])\n",
    "plt.axis(\"Off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Create and Compile Generator Model\n",
    "<img src=\"img/generator.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    generator = Sequential()\n",
    "\n",
    "    generator.add(Dense(units = 512, input_dim = 100))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 512))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 1024))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 784, activation = \"tanh\"))\n",
    "    \n",
    "    # 2 output olduğu için binary\n",
    "    generator.compile(loss = \"binary_crossentropy\", optimizer = Adam(learning_rate = 0.0001, beta_1 = 0.5))\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               51712     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               803600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,643,280\n",
      "Trainable params: 1,643,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = create_generator()\n",
    "g.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Create and Compile Discriminator Model\n",
    "<img src=\"img/discriminator.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "\n",
    "    discriminator.add(Dense(units=1024, input_dim = 784))\n",
    "    discriminator.add(ReLU())\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "    discriminator.add(Dense(units=512))\n",
    "    discriminator.add(ReLU())\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(ReLU())\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation = \"sigmoid\")) # 1 neron=output\n",
    "    \n",
    "    # beta_1=1. an tahminleri için üstel bozulma oranı. default=0,9\n",
    "    discriminator.compile(loss = \"binary_crossentropy\",\n",
    "                          optimizer= Adam(learning_rate = 0.0001, beta_1 = 0.5))\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 1024)              803840    \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d = create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Create and Compile GANs Model\n",
    "<img src=\"img/gans5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable = False # generatorun zamanla doğru resimler üretebilmesi için, d'nin train edilemez olması gerek.\n",
    "    \n",
    "    gan_input = Input(shape=(100,))\n",
    "    \n",
    "    # x = generatorun outputu\n",
    "    x = generator(gan_input) \n",
    "\n",
    "    # generatorun outputu, discriminatorun inputudur.\n",
    "    gan_output = discriminator(x)\n",
    "    \n",
    "    gan = Model(inputs = gan_input, outputs = gan_output)\n",
    "    \n",
    "    gan.compile(loss = \"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 784)               1643280   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 1460225   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,103,505\n",
      "Trainable params: 1,643,280\n",
      "Non-trainable params: 1,460,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Train Data\n",
    "<img src=\"img/train.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  0\n",
      "epochs:  1\n",
      "epochs:  2\n",
      "epochs:  3\n",
      "epochs:  4\n",
      "epochs:  5\n",
      "epochs:  6\n",
      "epochs:  7\n",
      "epochs:  8\n",
      "epochs:  9\n",
      "epochs:  10\n",
      "epochs:  11\n",
      "epochs:  12\n",
      "epochs:  13\n",
      "epochs:  14\n",
      "epochs:  15\n",
      "epochs:  16\n",
      "epochs:  17\n",
      "epochs:  18\n",
      "epochs:  19\n",
      "epochs:  20\n",
      "epochs:  21\n",
      "epochs:  22\n",
      "epochs:  23\n",
      "epochs:  24\n",
      "epochs:  25\n",
      "epochs:  26\n",
      "epochs:  27\n",
      "epochs:  28\n",
      "epochs:  29\n",
      "epochs:  30\n",
      "epochs:  31\n",
      "epochs:  32\n",
      "epochs:  33\n",
      "epochs:  34\n",
      "epochs:  35\n",
      "epochs:  36\n",
      "epochs:  37\n",
      "epochs:  38\n",
      "epochs:  39\n",
      "epochs:  40\n",
      "epochs:  41\n",
      "epochs:  42\n",
      "epochs:  43\n",
      "epochs:  44\n",
      "epochs:  45\n",
      "epochs:  46\n",
      "epochs:  47\n",
      "epochs:  48\n",
      "epochs:  49\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    for _ in range(batch_size):\n",
    "        \n",
    "        noise = np.random.normal(0,1, [batch_size,100])\n",
    "        \n",
    "        generated_images = g.predict(noise)\n",
    "        \n",
    "        # x_train'in ilk ve son indexi arasında random batch size kadar resim seçer.\n",
    "        image_batch = x_train[np.random.randint(low = 0, high = x_train.shape[0], size = batch_size)]\n",
    "        \n",
    "        # ilk 256 tanesi => gercek, son 256 tanesi => fake imageler olacak şekilde merge edilir.\n",
    "        x = np.concatenate([image_batch, generated_images])\n",
    "        \n",
    "        # d'leri eğitmek için gerekli olan resimlerin labellarına(y) ihtiyaç var.\n",
    "        y_dis = np.zeros(batch_size * 2) # 512 tane 0 oluşturur. (son 256 tanesi 0)\n",
    "        y_dis[:batch_size] = 1 # ilk 256 tanesini 1 olarak güncellenir\n",
    "        \n",
    "        d.trainable = True # Artık eğitime başladık.\n",
    "        d.train_on_batch(x, y_dis) # input olarak bu parametreler verilir.\n",
    "\n",
    "        ######################## TRAIN GENERATOR ########################\n",
    "\n",
    "        noise = np.random.normal(0, 1, [batch_size, 100]) # 0-1 arasında 256x100 lük bir noise oluşturulur.\n",
    "        \n",
    "        y_gen = np.ones(batch_size) # generator resimlerin gerçek resim olduğunu iddia ediyor, o yüzden 1'le doldurulur! :)\n",
    "        \n",
    "        d.trainable = False # artık generator eğitilecek.\n",
    "        \n",
    "        gan.train_on_batch(noise, y_gen) # input olarak bu parametreler verilir.\n",
    "    print(\"epochs: \", e)\n",
    "    \n",
    "g.save('demo.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(\"demo.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-Visualiza Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.64509782, -0.35197548,  0.84913277, ...,  0.50153618,\n",
       "         1.08220526, -3.28160216],\n",
       "       [ 0.74994833, -0.23390685,  0.39053153, ...,  1.02768636,\n",
       "        -0.83149205, -1.95445166],\n",
       "       [-1.21841654, -0.81404729,  0.39729674, ..., -0.31197976,\n",
       "         0.96442003,  0.34890993],\n",
       "       ...,\n",
       "       [-2.24545785,  0.55092833,  0.07647887, ...,  1.35136571,\n",
       "        -1.5346627 ,  0.56883921],\n",
       "       [-0.04048832,  1.83652184,  1.17422021, ...,  1.51133025,\n",
       "        -0.66080862,  0.01275371],\n",
       "       [-0.63695126,  1.07570348, -0.24085974, ...,  0.95549412,\n",
       "         0.04997536,  0.35381645]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(loc=0, scale=1, size=[100, 100])\n",
    "noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aşağıdaki plotlarda yalnızca 50 epoch ile gerçeğe çok yakın resimler elde edilmiş olduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_images = g.predict(noise)\n",
    "generated_images = generated_images.reshape(100, 28, 28)\n",
    "plt.imshow(generated_images[0], interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74156147804e2a01f94a3790aedbb2aa695f9a428eee8a505618a6d74e6c12c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
