{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48bb1394-d871-4670-812e-9e80ac87a27a",
    "_uuid": "84c59c4d97b2f0a0eb52a22d74e7939dd51873bf"
   },
   "source": [
    "## What is Pytorch?\n",
    "- It’s a Python based scientific computing package targeted at two sets of audiences:\n",
    "    - A replacement for NumPy to use the **power of GPUs**\n",
    "    - Deep learning research platform that provides maximum **flexibility** and **speed**\n",
    "- pros: \n",
    "    - Interactively debugging PyTorch. Many users who have used both frameworks would argue that makes pytorch significantly easier to **debug** and visualize.\n",
    "    - Clean support for dynamic graphs\n",
    "    - Organizational backing from Facebook\n",
    "    - Blend of high level and low level APIs\n",
    "- cons:\n",
    "    - Much less mature than alternatives\n",
    "    - Limited references / resources outside of the official documentation\n",
    "<br>\n",
    "<br>**Content:**\n",
    "1. [Basics of Pytorch](#1)\n",
    "    - Matrices\n",
    "    - Math\n",
    "    - Variable\n",
    "2. [Linear Regression](#2)\n",
    "3. [Logistic Regression](#3)\n",
    "4. [Artificial Neural Network (ANN)](#4)\n",
    "5. [Concolutional Neural Network (CNN)](#5)\n",
    "6. Recurrent Neural Network (RNN)\n",
    "    - https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch\n",
    "7. Long-Short Term Memory (LSTM)\n",
    "    - https://www.kaggle.com/kanncaa1/long-short-term-memory-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable # import variable from pytorch library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# 1-Basics of Pytorch\n",
    "## A. Matrices\n",
    "- In pytorch, matrix(array) is called tensors.\n",
    "- 3*3 matrix koy. This is 3x3 tensor.\n",
    "- Lets look at array example with numpy that we already know.\n",
    "    - We create numpy array with np.numpy() method\n",
    "    - Type(): type of the array. In this example it is numpy\n",
    "    - np.shape(): shape of the array. Row x Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensor.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    i) List to Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [[1,2,3],[4,5,6]]\n",
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0a70fde1-b9c4-47c5-aed7-1c863b2fd1e1",
    "_uuid": "d60e9b9f706124117b1d7ffcdeefb45b9aca45e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <class 'numpy.ndarray'>\n",
      "Array Shape: (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# numpy array\n",
    "first_array = np.array(list1) # 2x3 array\n",
    "print(\"Array Type: {}\".format(type(first_array))) # type\n",
    "print(\"Array Shape: {}\".format(np.shape(first_array))) # shape\n",
    "print(first_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "042b8e6f-0be6-43a1-96b4-49b32999a208",
    "_uuid": "28a4eb1e95add272552310eacf20740b895e43cd"
   },
   "source": [
    "- We looked at numpy array.\n",
    "- Now examine how we implement tensor(pytorch array)\n",
    "- import pytorch library with import torch\n",
    "- We create tensor with torch.Tensor() method\n",
    "- type: type of the array. In this example it is tensor\n",
    "- shape: shape of the array. Row x Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b383b085-a18f-4c18-a093-428336b6acf6",
    "_uuid": "126ea635dff4e2a6bc9a828dc560863e3be6aa74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <class 'torch.Tensor'>\n",
      "Array Shape: torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# pytorch array\n",
    "tensor1 = torch.Tensor(list1)\n",
    "print(\"Array Type: {}\".format(type(tensor1))) # type\n",
    "print(\"Array Shape: {}\".format(tensor1.shape)) # shape\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii. Allocate in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1f7ac29-8aa8-46ff-929f-94f2cedf7541",
    "_uuid": "fa1375fffab5b879eb828de7261e3e436ec15102"
   },
   "source": [
    "- Allocation is one of the most used technique in coding. Therefore lets learn how to make it with pytorch.\n",
    "- In order to learn, compare numpy and tensor\n",
    "    - **np.ones()** = **torch.ones()**\n",
    "    - **np.random.rand()** = **torch.rand()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "741468a5-5d91-48d7-95b0-6d02180d0c09",
    "_uuid": "2d36d68f3b57eef9d8f0ed94885f3376de92b414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# numpy ones\n",
    "print(\"Numpy: {}\\n\".format(np.ones((2,3))))\n",
    "\n",
    "# pytorch ones\n",
    "print(torch.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a578ff9f-df45-4acd-b5ec-2e26b2690adb",
    "_uuid": "1e6b8ce52af8a26ffc39fcd751a834ea7c870a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy [[0.87533619 0.76582744 0.05101395]\n",
      " [0.03696042 0.45249243 0.4098491 ]]\n",
      "\n",
      "tensor([[0.2560, 0.4036, 0.5710],\n",
      "        [0.2659, 0.5305, 0.6580]])\n"
     ]
    }
   ],
   "source": [
    "# numpy random\n",
    "print(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    iii. Convert from Numpy to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5177215-45b5-40c1-b838-2d0e3acb48ba",
    "_uuid": "22b5e44de713f58261bf1ff0b3a52b22a81ef1ef"
   },
   "source": [
    "- Even if when I use pytorch for neural networks, I feel better if I use numpy. Therefore, usually convert result of neural network that is tensor to numpy array to visualize or examine.\n",
    "- Lets look at conversion between tensor and numpy arrays.\n",
    "    - torch.from_numpy(): from numpy to tensor\n",
    "    - numpy(): from tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "f2cedc86-bd28-4709-906f-e236f4a4dbbe",
    "_uuid": "c6d3a7b8e0e42fcadecb16264b0563f74d01439a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.55649326 0.34807357]\n",
      " [0.83817526 0.43898714]]\n",
      "\n",
      "tensor([[0.5565, 0.3481],\n",
      "        [0.8382, 0.4390]], dtype=torch.float64)\n",
      "\n",
      "<class 'numpy.ndarray'> [[0.55649326 0.34807357]\n",
      " [0.83817526 0.43898714]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random numpy array\n",
    "array = np.random.rand(2,2)\n",
    "print(\"{} {}\\n\".format(type(array),array))\n",
    "\n",
    "# from numpy to tensor\n",
    "from_numpy_to_tensor = torch.from_numpy(array)\n",
    "print(\"{}\\n\".format(from_numpy_to_tensor))\n",
    "\n",
    "# from tensor to numpy\n",
    "tensor = from_numpy_to_tensor\n",
    "from_tensor_to_numpy = tensor.numpy()\n",
    "print(\"{} {}\\n\".format(type(from_tensor_to_numpy),from_tensor_to_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d7038e6-6aaf-4a1e-9204-406ab21082a2",
    "_uuid": "42cbe3900b733ab12867612d484d6fffaccd5e31"
   },
   "source": [
    "## B) Basic Math with Pytorch\n",
    "- Resize: **view()**\n",
    "- a and b are tensor.\n",
    "- Addition: torch.add(a,b) = a + b\n",
    "- Subtraction: a.sub(b) = a - b\n",
    "- Element wise multiplication: torch.mul(a,b) = a * b \n",
    "- Element wise division: torch.div(a,b) = a / b \n",
    "- Mean: a.mean()\n",
    "- Standart Deviation (std): a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.ones(3,3)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize\n",
    "tensor1.view(9).shape, tensor1.view(9) # vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.add(tensor1, tensor1) # Addition\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.sub(tensor1) # Subtraction => tensor2-tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor1, tensor2) # Element wise multiplication => tensor1xtensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor1, tensor2) # # Element wise division # tensor1 / tensor2 = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "e43af8e7-53ab-40bc-a4f8-4cea941c6df0",
    "_uuid": "66193cb3c790d13b8328c1c1262e1e3c17230bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0\n",
      "std: 1.5811388492584229\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.Tensor([1,2,3,4,5])\n",
    "print(\"Mean: {}\".format(tensor3.mean())) # Mean\n",
    "\n",
    "print(\"std: {}\".format(tensor3.std())) # Standart deviation (std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fb8b7d4-848a-4d2c-8436-162fd47a0e11",
    "_uuid": "ff85694eebe8d02701e20d7c15b0ad2974175dd3"
   },
   "source": [
    "## C) Variables\n",
    "- It accumulates gradients. \n",
    "- We will use pytorch in neural network. And as you know, in neural network we have backpropagation where gradients are calculated. Therefore we need to handle gradients. If you do not know neural network, check my deep learning tutorial first because I will not explain detailed the concepts like optimization, loss function or backpropagation. \n",
    "- Deep learning tutorial: https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners\n",
    "- Difference between variables and tensor is variable accumulates gradients.\n",
    "- We can make math operations with variables, too.\n",
    "- In order to make backward propagation we need variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "fd8ceaa3-f1e2-4761-924e-00a6daca4a82",
    "_uuid": "83e3222b53be71e5fc7207da552ce9e9b90486dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define variable\n",
    "var1 = Variable(torch.ones(3), requires_grad = True) # requires_grad= gradient bulma işlemi olacak.\n",
    "var1 # gradientleri depolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5d54144-0753-4e2a-bac1-ccfff3084f6e",
    "_uuid": "1cc3de04f98fc14624a18cceb5a84034b1dc29c7"
   },
   "source": [
    "- Assume we have equation y = x^2\n",
    "- Define x = [2,4] variable\n",
    "- After calculation we find that y = [4,16] (y = x^2)\n",
    "- Recap o equation is that o = (1/2)*sum(y) = (1/2)*sum(x^2)\n",
    "- deriavative of o = x\n",
    "- Result is equal to x so gradients are [2,4]\n",
    "- Lets implement\n",
    "\n",
    "<img src=\"img/variable.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is tensor: tensor([2., 4.])\n",
      "\n",
      "this is x variable: tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# lets make basic backward propagation\n",
    "# we have an equation that is y = x^2\n",
    "array1 = [2,4]\n",
    "tensor1 = torch.Tensor(array1)\n",
    "print(\"this is tensor:\", tensor1)\n",
    "\n",
    "x = Variable(tensor1, requires_grad = True)\n",
    "print(\"\\nthis is x variable:\", tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([ 4., 16.], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2  # y=x^2\n",
    "print(\"y =\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o =  tensor(10., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# recap o equation o = 1/2*sum(y)\n",
    "o = (1/2) * sum(y) # 1/2*(4+16)\n",
    "print(\"o = \", o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "cd73c1cf-d250-48e4-bfb7-ffbe8c03c267",
    "_uuid": "ff4010e2958a72ce45e43118790f3e20dc2abad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients:  tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# backward => x'e kadar backward yapar. Çünkü o y'den türer, y'de x'den türer.\n",
    "o.backward() # calculates gradients \n",
    "\n",
    "# As I defined, variables accumulates gradients. In this part there is only one variable x.\n",
    "# Therefore variable x should be have gradients\n",
    "# Lets look at gradients with x.grad\n",
    "print(\"gradients: \", x.grad) # x'i verir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
